{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0583b5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rag_assistant.rag_assistant import RAGAssistant\n",
    "from langchain_classic.retrievers import ParentDocumentRetriever\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter, MarkdownHeaderTextSplitter\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8076d386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInit signature:\u001b[39m\n",
      "ParentDocumentRetriever(\n",
      "    *args: Any,\n",
      "    name: str | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    tags: list[str] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    metadata: dict[str, typing.Any] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    vectorstore: langchain_core.vectorstores.base.VectorStore,\n",
      "    byte_store: Optional[langchain_core.stores.BaseStore[str, bytes]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    docstore: langchain_core.stores.BaseStore[str, langchain_core.documents.base.Document],\n",
      "    id_key: str = \u001b[33m'doc_id'\u001b[39m,\n",
      "    search_kwargs: dict = <factory>,\n",
      "    search_type: langchain_classic.retrievers.multi_vector.SearchType = <SearchType.similarity: \u001b[33m'similarity'\u001b[39m>,\n",
      "    child_splitter: langchain_text_splitters.base.TextSplitter,\n",
      "    parent_splitter: langchain_text_splitters.base.TextSplitter | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    child_metadata_fields: collections.abc.Sequence[str] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      ") -> \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mDocstring:\u001b[39m     \n",
      "Retrieve small chunks then retrieve their parent documents.\n",
      "\n",
      "When splitting documents for retrieval, there are often conflicting desires:\n",
      "\n",
      "1. You may want to have small documents, so that their embeddings can most\n",
      "    accurately reflect their meaning. If too long, then the embeddings can\n",
      "    lose meaning.\n",
      "2. You want to have long enough documents that the context of each chunk is\n",
      "    retained.\n",
      "\n",
      "The ParentDocumentRetriever strikes that balance by splitting and storing\n",
      "small chunks of data. During retrieval, it first fetches the small chunks\n",
      "but then looks up the parent IDs for those chunks and returns those larger\n",
      "documents.\n",
      "\n",
      "Note that \"parent document\" refers to the document that a small chunk\n",
      "originated from. This can either be the whole raw document OR a larger\n",
      "chunk.\n",
      "\n",
      "Examples:\n",
      "    ```python\n",
      "    from langchain_chroma import Chroma\n",
      "    from langchain_community.embeddings import OpenAIEmbeddings\n",
      "    from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
      "    from langchain_classic.storage import InMemoryStore\n",
      "\n",
      "    # This text splitter is used to create the parent documents\n",
      "    parent_splitter = RecursiveCharacterTextSplitter(\n",
      "        chunk_size=2000, add_start_index=True\n",
      "    )\n",
      "    # This text splitter is used to create the child documents\n",
      "    # It should create documents smaller than the parent\n",
      "    child_splitter = RecursiveCharacterTextSplitter(\n",
      "        chunk_size=400, add_start_index=True\n",
      "    )\n",
      "    # The VectorStore to use to index the child chunks\n",
      "    vectorstore = Chroma(embedding_function=OpenAIEmbeddings())\n",
      "    # The storage layer for the parent documents\n",
      "    store = InMemoryStore()\n",
      "\n",
      "    # Initialize the retriever\n",
      "    retriever = ParentDocumentRetriever(\n",
      "        vectorstore=vectorstore,\n",
      "        docstore=store,\n",
      "        child_splitter=child_splitter,\n",
      "        parent_splitter=parent_splitter,\n",
      "    )\n",
      "    ```\n",
      "\u001b[31mFile:\u001b[39m           c:\\users\\tkbar\\my projects\\ai_essentials\\.venv\\lib\\site-packages\\langchain_classic\\retrievers\\parent_document_retriever.py\n",
      "\u001b[31mType:\u001b[39m           ModelMetaclass\n",
      "\u001b[31mSubclasses:\u001b[39m     "
     ]
    }
   ],
   "source": [
    "ParentDocumentRetriever?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4610471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device being used in the embedding model is cpu\n",
      "\n",
      "RAG Assistant initialized successfully for topic: Blueprints for Text Analytics in Python textbook\n"
     ]
    }
   ],
   "source": [
    "assistant = RAGAssistant(persist_path=\"./chroma/rag\", collection_name=\"blueprint_text_analytics\", topic=\"Blueprints for Text Analytics in Python textbook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14b80535",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_db = assistant.vector_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49c24c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = vector_db.similarity_search_with_score(query=\"Summarize chapter 1 for me\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96041ded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(id='118dbb8b-b75a-43b1-a718-9db9988cd3ca', metadata={'Subtopic': '**Table of Contents**'}, page_content='Using Clustering to Uncover the Structure of Text Data                      236 Further Ideas                                                                                                                   240 Summary and Recommendation                                                                                 240 Conclusion                                                                                                                      241 **9. Text Summarization. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  243** What You’ll Learn and What We’ll Build                                                                   243 Text Summarization'),\n",
       "  0.49578702449798584),\n",
       " (Document(id='c11e862c-2713-441b-9999-0ecf3bf75260', metadata={'Subtopic': '**Blueprint: Summarizing Text Using an Indicator Representation**', 'Main Topic': '**Blueprint: Calculating Topic Distribution of Documents and Time Evolution**'}, page_content='event or series of events: the Mongol invasion of Europe. And since this is much longer text, we choose to summarize about 10 sentences to provide a better summary:'),\n",
       "  0.5214159488677979),\n",
       " (Document(id='4ae16f18-019f-4a27-bfab-ab283c222e53', metadata={'Main Topic': '**Blueprint: Calculating Topic Distribution of Documents and Time Evolution**', 'Subtopic': '**Text Summarization**'}, page_content='**243**  \\nreading course textbooks, lecture notes, or even this book, many students will try to highlight important sentences or make short notes to capture the important concepts. Automatic text summarization methods allow us to use computers to do this task.'),\n",
       "  0.5288925170898438),\n",
       " (Document(id='88069f56-08b7-4b67-aee0-591b36a79e37', metadata={'Subtopic': '**Blueprint: Summarizing Text Using an Indicator Representation**', 'Main Topic': '**Blueprint: Calculating Topic Distribution of Documents and Time Evolution**'}, page_content='**Blueprint: Summarizing Text Using an Indicator Representation | 251**  \\nwe will rely on the features of a sentence and the linkages between them rather than on topics contained in each sentence.'),\n",
       "  0.5327272415161133)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a15dfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = vector_db.search(query=\"Summarize chapter 1 for me\", search_type='mmr', k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5fe3c04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_results = assistant._format_docs_with_metadata(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cc6af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/structured_text.md\", \"r\", encoding='utf-8') as f:\n",
    "    structured_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5f84f8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=[(\"#\", \"Chapter\"), (\"##\", \"Topic\"), (\"###\", \"Blueprint\")],\n",
    "    strip_headers=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "10ec28d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown_content = markdown_splitter.split_text(structured_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "bcb488dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size = 1200,\n",
    "        chunk_overlap = 150\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "9573d96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = text_splitter.split_documents(markdown_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_essentials",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
